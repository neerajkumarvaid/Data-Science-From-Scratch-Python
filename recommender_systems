#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Tue Jan 21 14:48:22 2020

@author: Neeraj

Description: Implementation of user and item based collaborative filtering, and a matrix factorization algorithm in Python.

Reference: Chapter 23 : Recommender Systems


"""

users_interests = [
    ["Hadoop", "Big Data", "HBase", "Java", "Spark", "Storm", "Cassandra"],
    ["NoSQL", "MongoDB", "Cassandra", "HBase", "Postgres"],
    ["Python", "scikit-learn", "scipy", "numpy", "statsmodels", "pandas"],
    ["R", "Python", "statistics", "regression", "probability"],
    ["machine learning", "regression", "decision trees", "libsvm"],
    ["Python", "R", "Java", "C++", "Haskell", "programming languages"],
    ["statistics", "probability", "mathematics", "theory"],
    ["machine learning", "scikit-learn", "Mahout", "neural networks"],
    ["neural networks", "deep learning", "Big Data", "artificial intelligence"],
    ["Hadoop", "Java", "MapReduce", "Big Data"],
    ["statistics", "R", "statsmodels"],
    ["C++", "deep learning", "artificial intelligence", "probability"],
    ["pandas", "R", "Python"],
    ["databases", "HBase", "Postgres", "MySQL", "MongoDB"],
    ["libsvm", "regression", "support vector machines"]
]

from collections import Counter

popular_interests = Counter(interest for user_interests in users_interests for interest in user_interests)


from typing import List, Tuple

def most_popular_new_interest(user_interests: List[str],
                             max_results: int  = 5) -> List[Tuple[str, int]]:
    suggestions = [(interest, frequency) for interest, frequency in popular_interests.most_common()
                  if interest not in user_interests]
    
    return suggestions[:max_results]

unique_interests = sorted({interest for user_interests in users_interests
                          for interest in user_interests})


def make_user_interest_vector(user_interests: List[str]) -> List[int]:
    """Given a list of interests, produce a vector whose ith element is 1 if unique_interest[i]
    is in the list, else 0"""
    
    # create a list of zeros for all unique interests    
    return [1 if interest in user_interests else 0 for interest in unique_interests ]

user_interest_vectors = [make_user_interest_vector(user_interests) for user_interests in users_interests]

from vector_operations import Vector, dot
import math
def cosine_similarity(v1: Vector, v2: Vector) -> float:
    return dot(v1, v2)/math.sqrt(dot(v1,v1) * dot(v2,v2))

user_similarities = [[cosine_similarity(interest_vector_i, interest_vector_j)
                    for interest_vector_j in user_interest_vectors]
                    for interest_vector_i in user_interest_vectors]


# find most similar users

def most_similar_users_to(user_id: int) -> List[Tuple[int, float]]:
    pairs = [(other_user_id, similarity)
            for other_user_id, similarity in enumerate(user_similarities[user_id])
            if user_id != other_user_id and similarity >0]
    
    return sorted(pairs, key = lambda pair: pair[-1], reverse = True)



def user_based_suggestions(user_id: int,
                          include_current_interests: bool = False):
    # Sum up the similarities
    suggestions: Dict[str, float] = defaultdict(float)
    
    for other_user_id, similarity in most_similar_users_to(user_id):
        for interest in users_interests[other_user_id]:
            suggestions[interest] += similarity
            
    # convert them to sorted list
    
    suggestions = sorted(suggestions.items(), key = lambda pair: pair[-1], reverse = True)
    
    # And optionally remove already interests
    
    if include_current_interests:
        return suggestions
    else:
        return [(suggestions, weight) for suggestion, weight in suggestions
               if suggestion not in users_interests[user_id]]
    
interest_user_matrix = [[user_interest_vector[j] for user_interest_vector in user_interest_vectors]
                       for j, _ in enumerate(unique_interests)]

interest_similarities = [[cosine_similarity(user_vector_i, user_vector_j) 
                         for user_vector_j in interest_user_matrix]
                        for user_vector_i in interest_user_matrix]


def most_similar_interests_to(interest_id: int):
    similarities = interest_similarities[interest_id]
    pairs = [(unique_interests[other_interest_id], similarity)
            for other_interest_id, similarity in enumerate(similarities)
            if interest_id != other_interest_id and similarity > 0]
    
    return sorted(pairs, key = lambda pair: pair[-1], reverse = True)


                          include_current_interests: bool = False):
    
    # Add up the similar interests
    suggestions = defaultdict(float)
    
    user_interest_vector = user_interest_vectors[user_id]
    
    for interest_id, is_interested in enumerate(user_interest_vector):
        if is_interested == 1:
            similar_interests = most_similar_interests_to(interest_id)
            for interest, similarity in similar_interests:
                suggestions[interest] += similarity
                
    # sort them by weight
    suggestions = sorted(suggestions.items(), key = lambda pair: pair[-1], reverse = True)
    
    if include_current_interests:
        return suggestions
    else:
        return [(suggestion, weight) for suggestion, weight in suggestions
               if suggestion not in users_interests[user_id]]
    
MOVIES = "./ml-100k/u.item"
RATINGS = "./ml-100k/u.data"

from typing import NamedTuple

class Rating(NamedTuple):
    user_id: str
    movie_id: str
    rating: float
        
import csv
with open(MOVIES, encoding="iso-8859-1") as f:
        reader = csv.reader(f, delimiter="|")
        movies = {movie_id: title for movie_id, title, *_ in reader}
        
# Create a list of [Rating]
with open(RATINGS, encoding="iso-8859-1") as f:
    reader = csv.reader(f, delimiter="\t")
    ratings = [Rating(user_id, movie_id, float(rating))
                   for user_id, movie_id, rating, _ in reader]    

import re

# Data structure for accumulating ratings by movie_id
star_wars_ratings = {movie_id: []
                         for movie_id, title in movies.items()
                         if re.search("Star Wars|Empire Strikes|Jedi", title)}

# Iterate over ratings, accumulating the Star Wars ones
for rating in ratings:
    if rating.movie_id in star_wars_ratings:
        star_wars_ratings[rating.movie_id].append(rating.rating)
    
# Compute the average rating for each movie
avg_ratings = [(sum(title_ratings) / len(title_ratings), movie_id)
                   for movie_id, title_ratings in star_wars_ratings.items()]
        
random.seed(0)
random.shuffle(ratings)
    
split1 = int(len(ratings) * 0.7)
split2 = int(len(ratings) * 0.85)
    
train = ratings[:split1]              # 70% of the data
validation = ratings[split1:split2]   # 15% of the data
test = ratings[split2:]               # 15% of the data
    
avg_rating = sum(rating.rating for rating in train) / len(train)
baseline_error = sum((rating.rating - avg_rating) ** 2
                         for rating in test) / len(test)

# Embedding vectors for matrix factorization model
    
from deep_learning import random_tensor
    
EMBEDDING_DIM = 2
    
# Find unique ids
user_ids = {rating.user_id for rating in ratings}
movie_ids = {rating.movie_id for rating in ratings}
    
# Then create a random vector per id
user_vectors = {user_id: random_tensor(EMBEDDING_DIM)
                    for user_id in user_ids}
movie_vectors = {movie_id: random_tensor(EMBEDDING_DIM)
                     for movie_id in movie_ids}

rom typing import List
import tqdm
from vector_operations import dot
    
def loop(dataset: List[Rating],
            learning_rate: float = None) -> None:
    with tqdm.tqdm(dataset) as t:
        loss = 0.0
        for i, rating in enumerate(t):
            movie_vector = movie_vectors[rating.movie_id]
            user_vector = user_vectors[rating.user_id]
            predicted = dot(user_vector, movie_vector)
            error = predicted - rating.rating
            loss += error ** 2
    
            if learning_rate is not None:
                    #     predicted = m_0 * u_0 + ... + m_k * u_k
                    # So each u_j enters output with coefficent m_j
                    # and each m_j enters output with coefficient u_j
                user_gradient = [error * m_j for m_j in movie_vector]
                movie_gradient = [error * u_j for u_j in user_vector]
    
                    # Take gradient steps
                for j in range(EMBEDDING_DIM):
                    user_vector[j] -= learning_rate * user_gradient[j]
                    movie_vector[j] -= learning_rate * movie_gradient[j]
    
            t.set_description(f"avg loss: {loss / (i + 1)}")

for epoch in range(20):
    learning_rate *= 0.9
    print(epoch, learning_rate)
    loop(train, learning_rate=learning_rate)
    loop(validation)
loop(test)        
